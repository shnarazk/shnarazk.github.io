(window.webpackJsonp=window.webpackJsonp||[]).push([[64],{549:function(n){n.exports=JSON.parse('{"title":"UNSAT LOG, 2020, Feb.","subtitle":"Vol.1, No.2.","date":"2020-02-11T00:00:00.000Z","tags":["SAT","splr","unsatlog"],"bodyContent":"## はじめに\\n\\n今期のビッグイベントはなんと言ってもSplr-0.3.0のリリース。めでたい。\\n\\n## Splr-0.3.0リリース\\n\\n三ヶ月の開発期間を経て2月10日にようやくSplr-0.3.0をリリースすることができました。その更新内容から大事な部分を拾ってみると、\\n\\n1. 変数選択機構を最新のLearnt Rate based Branching with Reson Side Rewardingに基づくものに変更したこと。なお更新の単位は矛盾ではなく割当てから未割り当てまでで考えることにした。これは単なるアイデア。\\n1. タイムアウト用のスレッドを導入してEliminatorを残り時間を考えて自発的に中断するようにしたこと。こうしないと**大きな問題では何時間でも変数除去をやっていた**ようだ。\\n1. 変数活性度の減衰率が意外に重要だということがわかったのでやや小さめにしたこと。これは小さくする、すなわち学習による更新が稀にしか起きなくすることで、結局リスタート時に大きな変化を生じさせなくする効果があり、それはつまり**deep searchモードでリスタート発生を抑えようとしたのと同じような効果がある**らしいことがわかったから。このパラメータだけで求解数が大きく違う。またdeep searchの理解が少し進んだので、deep saerchの重みを減らした（期間の減少、定期的な通常モードへの復帰、クールダウン期間の減少など）。\\n1. あとは標準的なtraitを様々導入したこと。サブモジュール間のインターフェイスが変わったので0.2.2ではなく0.3.0にナンバリング。\\n\\nこれで6000行のプログラムの2000行ほどが更新されることになったし、質的にも結構大きな修正だった。多分この文章以外にはどこにも書かないだろうけど、上記強調部分は眼から鱗の出来事だった。\\n\\n## ChronoBTの試み\\n\\n前回から0.2.2の目玉として考えてきたChronoBTの実装は論文をちゃんと読んでみると、バックトラック時の再割り当ての手間を省くのは主目的ではなく、バックトラックコストが少ない学習節の作成から得られるむしろ副作用のようなものであることがわかった。ということでこれまでの安直な実装を目指していたブランチは全て見当外れ。0.3.0のリリース後に論文見ながら一からやり直すことになった。これが0.3.1の主目標になるでしょう。\\n\\n## ベンチマーク変更\\n\\nベンチマークをSAT Competition 2018ものからSAT RACE 2019に変更しました。過去のデータが使えなくなるのは大きいので延び延びになっていたけどようやく重い腰をあげた。下図が去年の公式データの結果のカクタスプロット（2つほどなんか変なデータがあったので除去が必要だった）。やはり500秒くらいで既にある程度の傾向は見て取れる。現実的な到達目標にしようと思う。これなら並列実行すれば今の環境でも1日掛からないくらいで1回のベンチマークを終わらせることができるし。\\n\\n![](/img/2020/02-11/cactus.png)\\n\\nさて、ここに（並列実行の影響補正用の適当なスケーリングありで）Splr-0.3.0でやってみた結果を追加してみると、絶望するほどじゃないじゃん。少なくとも下位グループの中位には位置づけできそうな感じだ。\\n\\nあとはChronoBTを導入することで、どこまで伸ばすことができるか。期待しよう。\\n\\nさらにJupyter labを導入しました。まあ慣れてしまえばいいことでRもPythonも同じようなもんだな。Pythonでプログラミングするつもりはないけど、まあ21世紀のPostScriptのようなもんだろう、図形表示言語という意味で。Rustカーネルも入れてみたけど、使いところがないなあ。\\n\\n## 結び\\n\\nさあChronoBTの実装だ！下位グループから脱却できるかなあ。","bodyHtml":"<h2>はじめに</h2>\\n<p>今期のビッグイベントはなんと言ってもSplr-0.3.0のリリース。めでたい。</p>\\n<h2>Splr-0.3.0リリース</h2>\\n<p>三ヶ月の開発期間を経て2月10日にようやくSplr-0.3.0をリリースすることができました。その更新内容から大事な部分を拾ってみると、</p>\\n<ol>\\n<li>変数選択機構を最新のLearnt Rate based Branching with Reson Side Rewardingに基づくものに変更したこと。なお更新の単位は矛盾ではなく割当てから未割り当てまでで考えることにした。これは単なるアイデア。</li>\\n<li>タイムアウト用のスレッドを導入してEliminatorを残り時間を考えて自発的に中断するようにしたこと。こうしないと<strong>大きな問題では何時間でも変数除去をやっていた</strong>ようだ。</li>\\n<li>変数活性度の減衰率が意外に重要だということがわかったのでやや小さめにしたこと。これは小さくする、すなわち学習による更新が稀にしか起きなくすることで、結局リスタート時に大きな変化を生じさせなくする効果があり、それはつまり<strong>deep searchモードでリスタート発生を抑えようとしたのと同じような効果がある</strong>らしいことがわかったから。このパラメータだけで求解数が大きく違う。またdeep searchの理解が少し進んだので、deep saerchの重みを減らした（期間の減少、定期的な通常モードへの復帰、クールダウン期間の減少など）。</li>\\n<li>あとは標準的なtraitを様々導入したこと。サブモジュール間のインターフェイスが変わったので0.2.2ではなく0.3.0にナンバリング。</li>\\n</ol>\\n<p>これで6000行のプログラムの2000行ほどが更新されることになったし、質的にも結構大きな修正だった。多分この文章以外にはどこにも書かないだろうけど、上記強調部分は眼から鱗の出来事だった。</p>\\n<h2>ChronoBTの試み</h2>\\n<p>前回から0.2.2の目玉として考えてきたChronoBTの実装は論文をちゃんと読んでみると、バックトラック時の再割り当ての手間を省くのは主目的ではなく、バックトラックコストが少ない学習節の作成から得られるむしろ副作用のようなものであることがわかった。ということでこれまでの安直な実装を目指していたブランチは全て見当外れ。0.3.0のリリース後に論文見ながら一からやり直すことになった。これが0.3.1の主目標になるでしょう。</p>\\n<h2>ベンチマーク変更</h2>\\n<p>ベンチマークをSAT Competition 2018ものからSAT RACE 2019に変更しました。過去のデータが使えなくなるのは大きいので延び延びになっていたけどようやく重い腰をあげた。下図が去年の公式データの結果のカクタスプロット（2つほどなんか変なデータがあったので除去が必要だった）。やはり500秒くらいで既にある程度の傾向は見て取れる。現実的な到達目標にしようと思う。これなら並列実行すれば今の環境でも1日掛からないくらいで1回のベンチマークを終わらせることができるし。</p>\\n<p><img src=\\"/img/2020/02-11/cactus.png\\" alt=\\"\\"></p>\\n<p>さて、ここに（並列実行の影響補正用の適当なスケーリングありで）Splr-0.3.0でやってみた結果を追加してみると、絶望するほどじゃないじゃん。少なくとも下位グループの中位には位置づけできそうな感じだ。</p>\\n<p>あとはChronoBTを導入することで、どこまで伸ばすことができるか。期待しよう。</p>\\n<p>さらにJupyter labを導入しました。まあ慣れてしまえばいいことでRもPythonも同じようなもんだな。Pythonでプログラミングするつもりはないけど、まあ21世紀のPostScriptのようなもんだろう、図形表示言語という意味で。Rustカーネルも入れてみたけど、使いところがないなあ。</p>\\n<h2>結び</h2>\\n<p>さあChronoBTの実装だ！下位グループから脱却できるかなあ。</p>\\n","dir":"article/.json/2020","base":"2020-02-11-UNSATlog.json","ext":".json","sourceBase":"2020-02-11-UNSATlog.md","sourceExt":".md"}')}}]);
<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>Just a Note</title>
        <link>https://shnarazk.github.io</link>
        <description>a collection of memo</description>
        <lastBuildDate>Tue, 22 Jun 2021 09:31:54 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>nuxtjs/feed</generator>
        <item>
            <title><![CDATA[Scratchでの変数のスコープ]]></title>
            <link>https://shnarazk.github.io/2021/2021-06-22-scope-of-vars-in-Scratch</link>
            <guid>https://shnarazk.github.io/2021/2021-06-22-scope-of-vars-in-Scratch</guid>
            <pubDate>Tue, 22 Jun 2021 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[Scratchはイベント発火やメッセージベースで同期を取るマルチスレッドシステムとしてコーディングするのが簡単。
これだとあまり変数の必要性を感じない。
ただし、高度なことをするためにはもちろん関数や変数による状態管理をせざるを得ない。

で、変数を定義するのだけども、定義時にのみ共有レベルが指定できる。

![](/img/2021/06-22-scratch/define-var.png)

ここでグローバルを選ばないと、その変数は他スプライトからは見えないのだろうが、ではクローンされたスレッド間ではどうなるのだろう。その理解が必要となる。

## 結論

- `すべてのスプライト用` -- 全てのスプライト、全てのクローンで共有。完全にglobal。
- `このスプライトのみ` -- スコープはこのスプライトのみ、スプライトのクローンにより変数もクローンされる。従ってthread l]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[ChoroBT再実装]]></title>
            <link>https://shnarazk.github.io/2021/2021-06-22-chronoBT</link>
            <guid>https://shnarazk.github.io/2021/2021-06-22-chronoBT</guid>
            <pubDate>Tue, 22 Jun 2021 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[どうもChronoBTの実装が間違っていたらしい。
散々バグを取ってきたはずのコードなんだけど今見直してみると、これでいいのか自信が持てない。
一旦機能削除するつもりで論文[1]に忠実に再実装することにした。

![The idea](/img/2021/06-22/Fig1.png)


![The modified CDCL](/img/2021/06-22/CDCL.png)


[1] A. Nadel and V. Ryvchin, “Chronological Backtracking,” in Theory and Applications of Satisfiability Testing - SAT 2018, no. June 2018, 2018, pp. 111–121.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Scratchでスプライト間コピペ]]></title>
            <link>https://shnarazk.github.io/2021/2021-06-15-copy-and-paste-in-scratch</link>
            <guid>https://shnarazk.github.io/2021/2021-06-15-copy-and-paste-in-scratch</guid>
            <pubDate>Tue, 15 Jun 2021 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[Scratchのコンテキストメニューに「複製」というのがあるのだけど、どうしても別スプライトに持っていけない。
なんか反応してそうな画面フィードバックはあるのだけど、あれは持っていけないよのグレイアウトだったようだ。

裏技ないかしらんと探していたら、なんとOSのコピペのショートカットが生きていた。
MacOSなら`コマンド-C`で最後にクリックしたブロックがコピーされ、
スプライト切り替えて`コマンド-V`でペーストできる。

これで、透視図法を使った3Dゲームを作るために、スプライトごとに3次元->2次元座標変換式を打ち込まなければならないという悲劇を避けることができた！]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[JIS配列のMacbookのかなキーで日本語入力モードをトグルしたい]]></title>
            <link>https://shnarazk.github.io/2021/2021-06-11-mac-keylayout</link>
            <guid>https://shnarazk.github.io/2021/2021-06-11-mac-keylayout</guid>
            <pubDate>Fri, 11 Jun 2021 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[## hidutilでなんとかしよう

US配列だと基本は(macbookでは)、こういうので日本語入力モードを切り替えることができる。

```
hidutil property --set '{"UserKeyMapping":[{"HIDKeyboardModifierMappingSrc":0x7000000e7,"HIDKeyboardModifierMappingDst":0x700000068}]}'
```

あるいは、最近だとmagic keyboardが対象だと下のようになる（以前は上ので問題なかったのだけど、OSのバージョンが上がって何か変わってしまったようだ）。

```
hidutil property --set '{"UserKeyMapping":[{"HIDKeyboardModifierMappingSrc":0x7000000e7,"HIDKeyboa]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[UNSAT LOG, 2021, Jun.]]></title>
            <link>https://shnarazk.github.io/2021/2021-06-05-UNSATlog</link>
            <guid>https://shnarazk.github.io/2021/2021-06-05-UNSATlog</guid>
            <pubDate>Sat, 05 Jun 2021 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[# 進歩と停滞の5月

5月はとうとう充足性判定問題のバグが（おそらく）取れたという大きな進展がありました。
一方このバージョンは0.7より圧倒的に遅くなってしまいました。
どうしよう。
色々見比べているのだけども、論理的無謬性が保証された状態変化のみを起こすためのコード書き換えのせいとしか思えないのだけど、では、だからと言って、revertする気にはなれないし。

また途方に暮れて開発ペースがグッと落ちてしまいました。
バグあり0.7の置き換えは早いところリリースしなければ行けないのだけどなあ。

開発サボって何やっていたかというとBlender。
授業で使っているので泥縄でも勉強しなければならない。
やっているうちに面白くなってきた。
モデリングやレンダリングはMayaとの類推で大体マニュアル見なくてもわかるけど、データの再利用とかビデオトラッキングとか新しいことも多くて、最近はCPU]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[UNSAT LOG, 2021, May]]></title>
            <link>https://shnarazk.github.io/2021/2021-05-01-UNSATlog</link>
            <guid>https://shnarazk.github.io/2021/2021-05-01-UNSATlog</guid>
            <pubDate>Sat, 01 May 2021 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[## vivificationの4月
Clause vivificationのバグが取れない4月でした。
これに尽きる。
一体何が起きているのやら。

UNSAT certificateの問題だけではなく、時々充足性判定すら間違うという状況が一ヶ月続いていて、一向に改善すら見られぬ状況。
しかし、これの解決なくして先に進むこともままならないわけで。
というわけでこれ以上今月は言うことなし。
強いて言うなら自分のメモも兼ねて、片っ端からbugをissue化していったくらい。まあこれはいいgithubの使い方なんだろう。まさに日記代わり。

- https://github.com/shnarazk/splr/issues/96
- https://github.com/shnarazk/splr/issues/104
- https://github.com/shnarazk/splr/is]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[New Implementation of clause vivifier on Splr-0.8]]></title>
            <link>https://shnarazk.github.io/2021/2021-04-10-splr-vivification</link>
            <guid>https://shnarazk.github.io/2021/2021-04-10-splr-vivification</guid>
            <pubDate>Tue, 04 May 2021 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[### 2021-04-10

Splr-0.7.1で発見された決定性誤りバグの一因がどうもvivificationにあるようなので、徹底的に見直してみた。
その結果、バグ修正の副産物として大変更に至りました。

これまではひたすら論文[1]のオリジナル疑似コードに忠実な実装を心がけていた:

![](/img/2020/07-05/vivi-algo3.jpg)

ここで`confilctAnalysis`の引数は

1. $\phi$ -- 論理式式
1. $D$ -- 仮定されたリテラル列（なぜtrailではいけないのだろう）
1. $R$ - 矛盾節

見ての通り、節を追加して伝播させて、節を削除して、ということを繰り返している。
そのためsandboxなんてものをサブモジュールに追加したりしていたのだけど、この"clause vivification"とは

- 節に含まれるリテ]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[UNSAT LOG, 2021, Apr.]]></title>
            <link>https://shnarazk.github.io/2021/2021-04-10-UNSATlog</link>
            <guid>https://shnarazk.github.io/2021/2021-04-10-UNSATlog</guid>
            <pubDate>Sat, 10 Apr 2021 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[# 充足性判定誤りの3月

Splr-0.7シリーズのポイントリリース0.7.1をサクサク公開して、いよいよ並列化という大物に取り掛かるつもりだったのが、ベンチマークの結果の検証で論理バグが検出されて、思いも掛けない終わりのないデバッグに突入してしまいました。
なんと0.7.1でエンバグしたのではなく、0.7.0が既におかしい。
いやもしかするとそれ以前からあったのかもしれない。
SATソルバーを名乗れないものをリリースしてしまっていた！

その上このことに気づいてから1週間経ってもバグが取れない！
時間がかかってしまう理由が簡単な問題では再現しないバグであること。
ベンチマークを走らせて検証スクリプトを走らせるとただ1問だけ不適切な充足解を生成している。
その問題は0.7.1RCで初めて解けるようになって、それ以前のソルバーではタイムアウトしてしまう問題。
なので色々なフィーチャーを切っ]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[UNSAT LOG, 2021, Mar.]]></title>
            <link>https://shnarazk.github.io/2021/2021-03-28-UNSATlog</link>
            <guid>https://shnarazk.github.io/2021/2021-03-28-UNSATlog</guid>
            <pubDate>Mon, 05 Apr 2021 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[# UNSATlog

## Splr-0.7.1リリースのはずが

前号を出したのが12日でそれから2週間足らずなので、Splr-0.7.1をリリースしたことしか書くことないよなあと思っていたら、リリース前のルーチンワークのベンチマークの検証中にエラーが発見されてしまった。

まさか、UNSAT問題をSATと答えるなんて！
それも、原因モジュールの同定に数時間かかることになってしまって、半日経っても何が問題なのかすら判明できていない有様。
ちょっとこのバグはキツい。リリースは（楽観的にみて）1週間ほど延期になりそうだ。

という以上の内容だけでvol.3を出して、Splr-0.7.1のリリースのタイミングで次の号を出し、そこで UNSAT logの号数を実暦に合わせよう。ああ、それだけが楽しみ。

## 2021-04-02

やっと、やっと、原因の節が特定できそう。`watch`が適切]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[衝撃の320変数3-SAT]]></title>
            <link>https://shnarazk.github.io/2021/2021-03-16-3SAT-SC20-170058143</link>
            <guid>https://shnarazk.github.io/2021/2021-03-16-3SAT-SC20-170058143</guid>
            <pubDate>Wed, 17 Mar 2021 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[まともなSAT solverなら250変数の3-SATなんて1秒程度で解け、その求解速度なんてなんの尺度にもならないものだろう。
なので最近のSplrの開発は360変数の3-SATをマイクロベンチマークに使っている。
最近はまあ「そこそこ待ち遠しくない時間」でSAT問題、UNSAT問題どちらも解けるようになってきていた。
で、やっとSAT competition 2021での問題をつまみ食いし始めたのだけど、ある問題に衝撃を受けてしまった。

それはSATな320変数3-SAT問題170058143.cnf。解けて当然だと思ってたのだが、5000秒タイムアウトで解けない。
色々設定変えて、やっと解けたらこんな感じ：

```
$ splr ~/Library/SAT/SC20/170058143.cnf
170058143.cnf                              ]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Nix flakeの作り方]]></title>
            <link>https://shnarazk.github.io/2021/2021-03-14-nix-flakes</link>
            <guid>https://shnarazk.github.io/2021/2021-03-14-nix-flakes</guid>
            <pubDate>Tue, 16 Mar 2021 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[2021-03-08にnix-2.4のpre-release版が三ヶ月ぶりに更新されて、ようやくnixを置き換えてもエラーなく使えるようになりました。（いやそうでもないみたいだぞ。。。@2021-03-16）
なので早速Splrで使ってみたのでいくつかメモ。

## restricted modeとは

`nix-env -u`でエラーはなくなったものの、flake.nixを作ろうとすると相変わらずrestricted modeではxxxxにアクセスできないというようなエラーが出る。これは`--impure`フラグを渡してやるといい。`nix --help`によると、

> When the --expr option is given, all installables are interpreted as Nix expressions.
> You may need to speci]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[UNSAT LOG, 2021, Feb.]]></title>
            <link>https://shnarazk.github.io/2021/2021-03-09-UNSATlog</link>
            <guid>https://shnarazk.github.io/2021/2021-03-09-UNSATlog</guid>
            <pubDate>Fri, 12 Mar 2021 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[# UNSAT log

## 2月の振り返り

2月はSplr-0.6シリーズのポイントリリースを2つ。
まあ大したものではないのだけど、内部的にはイオンという考え方について色々試してみた。
そして3月になってからリリースされた0.7.0で結局削除ということになりました。
これも含め0.7.0はうまくいかないアイデアを結構整理して削除するようなリリースとなりました。

## イオン

非常に単純化してSAT求解過程のモデルを作るなら、無矛盾なリテラル集合を大きくしていく過程をイメージするのがいいだろう。
この集合には変数活性度が高いものから組み込まれていく。
なので、ここに含まれていない変数は大きな活性度は持っていないはずである。
逆にこの条件を満足しない変数はそれ自身がある種のブロッカーすなわち「求解の妨げとなる変数」になっていると思われるので、（導入したステージベースのvar boo]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[UNSAT LOG, 2021, Jan.]]></title>
            <link>https://shnarazk.github.io/2021/2021-02-02-UNSATlog</link>
            <guid>https://shnarazk.github.io/2021/2021-02-02-UNSATlog</guid>
            <pubDate>Tue, 02 Feb 2021 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[# UNSATlog


## 202101

あけまして[Splr-0.6.0](https://github.com/shnarazk/splr/releases/tag/splr-0.6.0)出ました。
それどころか[0.6.1](https://github.com/shnarazk/splr/releases/tag/splr-0.6.1)も[0.6.2](https://github.com/shnarazk/splr/releases/tag/Splr-0.6.2)も出ました。
いやあ長かった。
その割にはむしろ圧倒的に性能劣化してしまってますが十分にベンチマークを回すだけのリソースがないんだからしょうがない。
どうでもいい「やってみたらよくなった」的な高速化は捨てる方向に舵を取ったのは長期的にはいい判断だと思いたい。

## What’s Splr-0.6.0?

Splr]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Rust製のSATソルバーで144x144のSudokuを解こう]]></title>
            <link>https://shnarazk.github.io/2021/2021-01-17-sudoku144</link>
            <guid>https://shnarazk.github.io/2021/2021-01-17-sudoku144</guid>
            <pubDate>Sun, 17 Jan 2021 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[着々と巨大なSudokuが解けるようになったのでどんどん行きましょう。
largeとかgiantとかを追加キーワードにして検索してとてもよさそうな[サイト](https://sudokugeant.cabanova.com/noflash.html)を見つけたけど、そのサイトはflashで書いてあって一切見れない。
なんという時代（技術）の断絶！

ただ[チャットページ](http://forum.enjoysudoku.com/giant-sudoku-s-16x16-25x25-36x36-100x100-t6578.html)が生きていたのでなんとか144x144とか400x400の問題を見つけることができました。

ということで[144x144 sudoku](http://forum.enjoysudoku.com/giant-sudoku-s-16x16-25x25-36x36]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[UNSAT LOG, 2020, Dec.]]></title>
            <link>https://shnarazk.github.io/2021/2021-01-02-UNSATlog</link>
            <guid>https://shnarazk.github.io/2021/2021-01-02-UNSATlog</guid>
            <pubDate>Sat, 02 Jan 2021 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[# UNSATlog

## 2020年振り返り

結局0.5.1はリリースできませんでした。12月にやったことは

- リフェーズ(re-phasing to best phase)に関するチューニング
- Sudoku 64への応用
- Advent of Code 2020への応用

というあたり。
個人的には、初めてVec以外のデータ構造(HashMap)を導入したことが大きいです。
やはりリリース直前のベンチマークに時間を取られてしまったものの、ドキュメントの更新は終わっているので、ベンチマークさえいい結果、いやよくなくてもいいのでそこそこの結果が出ればリリースするつもりなので、最速で2021年元旦に出せるはず。

## Best Phase Rewarding

Rephasingの実現手法として変数のrewardに反映させてみた。活性度に反映させるのではなく独立した項目にして]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Rust製のSATソルバーで64x64のSudokuが解けるだろうか]]></title>
            <link>https://shnarazk.github.io/2020/2020-12-18-sudoku64</link>
            <guid>https://shnarazk.github.io/2020/2020-12-18-sudoku64</guid>
            <pubDate>Fri, 18 Dec 2020 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[Splr-0.6.0のリリース直前のベンチマークをしながら、息抜きでもっと大きなSudokuを探してみました。

http://www.sudoku-download.net/sudoku_64x64.php

さあこの問題を[Splrで解いてみよう](https://github.com/shnarazk/sudoku_sat/blob/master/src/bin/sudoku64.rs)。

元データがpdfしかないので人手で取り込み、変換、間違いの修正に3時間掛かって、ようやくSplrの出番。20秒で正解でした。

大きさの割に空欄が少ないのでN=25と比べてそんなに計算量は増えないだろうと思ったのが2桁近く増えてしまった。なかなか勘はあたらないものだなあ。
ちなみに生成されるCNFの大きさはこんな感じ。

* 変数数: 262144 = (2^6)^3 = 1M * 2^(-2)]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[UNSAT LOG, 2020, Nov.]]></title>
            <link>https://shnarazk.github.io/2020/2020-12-04-UNSATlog</link>
            <guid>https://shnarazk.github.io/2020/2020-12-04-UNSATlog</guid>
            <pubDate>Fri, 04 Dec 2020 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[# 冬眠への道

今年もいよいよあと一ヶ月となってきました。夏からずっと取り組んでいるSplrのバージョン0.5.1はおそらく0.6.0としてリリースすることになると思うけどもう少し時間かかりそう。Splrの新版がリリースできたら今年の残りは勉強と研究に当てようと思う。絶対、論文読んだ方がいいよなあ。読みかけの専門書も溜まっているし。おっと、その前に夏休みの宿題を終わらせねば。節の有効性と取得環境の関係についてというテーマでいいはずだけど。積み残しが山のようだ。これではとても一ヶ月で終わりそうにないな。

# Sudoku25

今月はSudoku25に振り回された一ヶ月でした。実はSAT符合化に問題があったのでCNFファイルを作り直したら一瞬で解けるようになったものの、それ以前は1日CPUをぶん回しても解けなかったので色々とソルバーに手を入れてました。

```text
$ cargo ]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[JSONファイルをドラッグ&ドロップする]]></title>
            <link>https://shnarazk.github.io/2020/2020-11-08-Drop-a-JSON-file</link>
            <guid>https://shnarazk.github.io/2020/2020-11-08-Drop-a-JSON-file</guid>
            <pubDate>Sun, 08 Nov 2020 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[画像ファイルとかURLとかをドロップする話はそこそこ見つかるけど、JSONファイルをドロップするのに手こずったのでメモ。

```swift
  NavigationView { ... }
  .onDrop(of: ["public.json"], isTargeted: nil) { providers, location in
       if let item = providers.first {
           item.loadItem(forTypeIdentifier: "public.json", options: nil) { (urlData, error) in
               if let url = urlData as? URL {
                   self.json = loadJson(url: url)
 ]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[LubyStabilization]]></title>
            <link>https://shnarazk.github.io/2020/2020-11-07-LubyStabilization</link>
            <guid>https://shnarazk.github.io/2020/2020-11-07-LubyStabilization</guid>
            <pubDate>Wed, 18 Nov 2020 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[Luby seriesでstabilizationする。まだ結果が出てないだけども、これはいいかも！

### 2020-11-18

Luby Stabilization だかLuby Un-stabilization だか。

### 2020-11-20

今やろうとしていることはrandom walkの導入に類することかも知れぬ。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[SATソルバのベンチマークについて]]></title>
            <link>https://shnarazk.github.io/2020/2020-11-03-minimize-the-worst</link>
            <guid>https://shnarazk.github.io/2020/2020-11-03-minimize-the-worst</guid>
            <pubDate>Tue, 03 Nov 2020 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[SATソルバの性能を議論する唯一の指標はSAT competition で使われている400問のベンチマークの求解数だけだろう。
しかしその評価は膨大な計算機リソースを必要とし、正直なところ個人ベースでは現実的でない。なので、これまでは外挿可能だろうという楽観的な見通しの下、極めて短いタイムアウトを設定して実験を繰り返してきた。さらにその前段のスクリーニングとして `SAT-bench` による3-SAT問題中心のマイクロベンチマークを実行して、合計実行時間の短縮と短いタイムアウト時間内での求解数の向上とを改善指針にしてきた。

しかしこれは過学習の危険性が避けられない。これまではこの問題は敢えて無視してきたけど、泥沼のようなパラメータチューニングはそれでも避けられないため、[ちょっとしたパラメータチューニングのつもりで始めた改良ですら二ヶ月が経ってしまう](/2020/2020-10-3]]></content:encoded>
        </item>
    </channel>
</rss>